{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df0979c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from timeit import default_timer as timer\n",
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "919a59cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ESS8_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17ef6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['SD1', 'PO1', 'UN1', 'AC1', 'SC1',\n",
    "       'ST1', 'CO1', 'UN2', 'TR1', 'HD1', 'SD2','BE1','AC2', 'SC2', 'ST2',\n",
    "       'CO2', 'PO2', 'BE2', 'UN3', 'TR2','HD2']].iloc[range(100),:]\n",
    "X = X.to_numpy().T\n",
    "N, M = X.T.shape\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47234b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies both for eq. 7 and 8\n",
    "def error(a_i,Qt,qt):\n",
    "    return (0.5 * a_i.T @ Qt @ a_i) - (qt.T @ a_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef6089",
   "metadata": {},
   "source": [
    "## Defining the helper functions applyConstraints and furthestSum\n",
    "\n",
    "applyConstrants ensures that the constraints of the problem are upheld i.e. $e_{ij} \\geq 0$ and $1^T \\textbf{e}_j = 1$\n",
    "\n",
    "\n",
    "furthestSum is an effective way to initialize the values of $\\textbf{b}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec2091d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyConstrainsArray(M):\n",
    "    return softmax(M, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "def applyConstrainsTensor(M):\n",
    "    return #.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8101bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def furthestSum(X):\n",
    "    # Choose a random point for initialization\n",
    "    idx = int(np.random.choice(range(0,N)))\n",
    "    x_j = X[:,idx]\n",
    "\n",
    "    j_news = list()\n",
    "    j_news.append(idx)\n",
    "\n",
    "    excluded = [idx]\n",
    "\n",
    "    # Loop over the K archetypes\n",
    "    for n in range(K):\n",
    "        best_val = 0\n",
    "        best_idx = 0\n",
    "        # Loop over all unseen samples\n",
    "        for i in range(N-len(excluded)):\n",
    "            if i not in excluded:\n",
    "                val = 0\n",
    "                # sum over each element for each point\n",
    "                for ele in j_news:\n",
    "                    for j in range(M):\n",
    "                        \n",
    "                        val += np.abs(X[j,i] - X[j , ele])\n",
    "                if val > best_val:\n",
    "                    best_val = val\n",
    "                    best_idx = i\n",
    "                    \n",
    "        # \n",
    "        j_news.append(int(best_idx))\n",
    "        excluded.append(best_idx)\n",
    "        # Remove the random initialization\n",
    "        if n == 0:\n",
    "            j_news.pop(0)\n",
    "            excluded.pop(0)\n",
    "        \n",
    "    return j_news\n",
    "\n",
    "\n",
    "#init_vals_b = X[init_idxs[i],:].astype(np.float64)\n",
    "#init_vals_bt = torch.tensor(init_vals_b, requires_grad = False).float()\n",
    "\n",
    "#init_vals_b.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694a1cd",
   "metadata": {},
   "source": [
    "## Initializing variables for AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "120d3834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eb8ce3a5d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing Z through furthest sum\n",
    "#Z = X[:,furthestSum(X)]\n",
    "import random\n",
    "Z = X[:,random.sample(range(1, M), K)]\n",
    "print(Z.shape)\n",
    "R = X.T @ X\n",
    "Rt = torch.tensor(X.T @ X,requires_grad=False).float()\n",
    "\n",
    "RSS_values = list()\n",
    "A = np.zeros((K,N))#.tolist()\n",
    "B = np.zeros((N,K))#.tolist()\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62f0513f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(789.0945, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(416.0961, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(694.3499, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(200.2817, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.3585, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.6309, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(538.1461, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(580.1072, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(684.3636, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(274.5775, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(57.1619, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(573.2366, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(315.3781, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.3409, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.9496, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(268.0377, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(175.1602, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.4431, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(578.3174, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.9276, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(49.4328, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(82.8306, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(371.1699, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.2990, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(54.9836, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(236.6675, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(686.9150, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.8681, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(221.3438, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(806.3693, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(86.2949, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(207.2958, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(364.7152, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(260.3900, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.5020, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(321.3445, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(300.0396, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(225.9975, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(615.4878, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(335.4227, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(121.9533, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(16.4429, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(146.6775, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(565.4977, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(61.4538, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(326.8290, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(424.8587, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.7076, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(151.4555, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.0436, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(86.0173, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(128.8573, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(392.5201, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(400.6244, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(959.9017, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(216.5388, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(13.9339, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(512.2944, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(60.2267, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.7991, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(32.8042, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(294.7645, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(632.9811, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(616.8985, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(160.7334, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(70.3599, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(163.5287, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.4890, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(33.0822, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.0895, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(451.0607, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(241.7245, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.8537, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.4808, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(368.6857, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(395.3908, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(646.1817, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(653.3328, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(562.0722, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(74.6432, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(133.6131, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(10.6570, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(490.1133, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(35.8851, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(158.9080, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(70.1424, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(425.3495, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(299.9368, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(402.7873, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(243.0638, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(84.9410, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(522.3671, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(159.3957, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(393.6634, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(653.6069, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(172.6737, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(256.0603, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(333.6418, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(326.4470, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(237.9257, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(624.8334, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(250.8702, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(50.4122, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(121.8008, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(695.2952, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.2830, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(683.6562, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(59.5329, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(145.4196, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(747.1132, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(173.1375, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(353.2630, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.5678, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(89.5635, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(238.7428, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(51.3571, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(681.6347, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(275.8239, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(253.3049, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(57.6398, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(44.0260, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(256.8819, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(622.8588, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(42.7196, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(4.3365, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.5246, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(169.7150, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(153.3946, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(418.4926, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(21.6686, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(700.4246, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(93.2145, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(98.8997, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(316.1649, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(425.0328, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(123.9050, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(441.3287, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(31.2274, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(917.4640, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(555.0840, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(114.9268, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(3.5226, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(183.7580, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(307.7328, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(416.9977, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(32.5225, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(364.2386, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(604.5864, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(807.8803, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.8603, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(319.0120, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(20.6556, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.4888, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(287.2871, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(175.1741, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(110.6260, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(302.1956, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(52.7213, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(2.1452, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.1685, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(62.8044, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(291.9218, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(284.3823, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(378.9233, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(196.2063, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(402.2027, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(110.5634, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(138.6390, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(13.1124, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(210.0560, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(373.4656, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1148.8486, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(184.7857, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(579.9305, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(281.4051, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(367.7682, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(782.6187, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(294.0670, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(227.9999, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(118.1611, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(659.8676, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(356.9483, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(486.9680, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(99.6444, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(47.7754, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(103.9606, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(161.6613, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(92.6023, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(0.8775, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(32.2621, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(236.4305, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.2341, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(38.0370, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(753.8375, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(222.9140, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(651.9932, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(563.3518, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(360.1202, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(90.4694, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(2.5054, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(202.0741, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(4.1688, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(39.6222, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(582.0170, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.5379, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(211.1031, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(161.7460, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(444.8050, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(38.8386, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(155.2680, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(302.3123, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(105.5148, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(373.1524, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1074.8943, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(761.1423, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(154.7825, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.7816, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(454.7225, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(456.9996, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(392.4808, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(264.2158, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(585.9897, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(141.7222, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(647.7529, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(72.0194, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(354.9822, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.0416, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(11.0645, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(87.0758, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(95.9758, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(185.3744, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(336.1644, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(816.2095, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(310.5015, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(337.9891, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1044.3052, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(30.2647, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(228.8158, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(93.5806, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(53.0235, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(241.7811, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(286.9678, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1173.0708, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(894.7227, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(0.8871, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(290.7559, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(483.9376, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.9842, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(253.1187, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(90.0246, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(168.2178, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(571.3206, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(79.5914, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(354.4141, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(342.1285, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(710.0499, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(52.0834, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(422.5745, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(858.6443, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(499.4522, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(88.3356, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(455.4709, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(360.0494, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.7989, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.4042, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.8801, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(438.0965, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(832.0057, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(272.0124, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(26.0497, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(415.2020, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(67.8268, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(75.0728, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(40.0762, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(69.8031, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(777.2747, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(341.5741, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(59.2842, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(366.6768, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.4533, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1.0917, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(90.2185, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(20.3399, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(127.1638, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(104.3560, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(2.2638, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(525.4023, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(246.0543, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.7578, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.9549, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(513.6166, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(340.2292, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.1838, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(423.7350, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(439.0545, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(462.4942, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(10.1068, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(276.1468, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(78.1222, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(393.5165, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(324.3337, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(66.3658, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(468.2329, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(845.7912, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1299.4022, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(116.0040, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(392.1534, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(11.1032, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(707.7219, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(62.5752, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(501.8354, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(40.1534, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(295.5200, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(162.2326, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(31.4266, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(385.2999, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(24.6463, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(491.4572, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.0703, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(49.9333, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(31.1475, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(774.4136, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(42.9957, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(301.8317, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(205.8557, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(201.2971, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(221.7495, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.3817, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(249.5917, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.2250, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(124.8297, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(34.0890, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(334.2673, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(535.2990, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(204.8725, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(552.3839, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(611.1128, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(53.0700, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(319.4727, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(32.9363, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(201.3062, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(380.5632, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(365.5698, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(175.8209, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(18.5959, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(391.1884, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(145.9753, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(134.9773, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(498.5905, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(724.2990, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(717.3082, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(474.9101, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(59.1683, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(598.7902, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(243.5827, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(7.5157, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(454.8988, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(136.2494, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(291.6850, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(158.9178, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.3173, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(337.3521, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(399.8537, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(381.7115, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(234.1066, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(48.3018, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(154.2720, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(560.7897, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(222.7033, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(671.1897, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(911.7527, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1.2976, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(519.2703, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(817.1234, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(445.0475, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(363.3983, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(183.4478, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(188.5900, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(366.1283, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(310.0767, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(192.1968, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.6415, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.0356, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(506.9230, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(56.2384, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(412.3776, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(7.8468, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(166.7263, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(592.9601, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(551.1879, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.0964, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(512.0622, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(68.6803, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(169.0109, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(33.4883, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(362.8845, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(572.0768, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(164.1502, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(130.1322, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.7979, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(102.2608, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.1099, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(48.7669, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(95.2936, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(51.9862, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(305.0663, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(295.4261, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(80.1008, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.8136, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(522.4863, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.7642, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(231.7921, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(304.6396, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(316.7359, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(281.3625, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(645.0662, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(69.5194, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(697.8201, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(574.1010, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1.0565, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(257.7431, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(483.5205, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(651.2016, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(872.3981, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1016.2687, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(549.6783, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(444.1515, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(222.8029, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(949.8127, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(645.8259, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.2727, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(362.4883, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(535.1919, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(125.1255, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(84.4727, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(183.9955, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(83.6076, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(96.8733, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(33.9480, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(77.2020, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.1522, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(710.9182, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(502.6105, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.9240, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(450.9846, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(452.9648, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.1784, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(15.2031, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(95.5805, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(50.1191, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(39.1503, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(63.5790, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(153.3749, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(236.2875, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(853.0912, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.3398, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.2496, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(61.8044, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(189.8628, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.7054, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(11.7175, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(35.2036, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(517.0613, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(64.9565, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(691.3181, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(133.1359, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(264.5501, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(134.6296, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(321.6684, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(157.3044, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(182.2114, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(420.1638, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(317.3589, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(764.9023, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(120.6737, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(71.6930, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.6625, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(590.3836, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(3.7401, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(185.0799, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(62.6438, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(20.9576, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.0208, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(507.8419, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(175.7291, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(484.1749, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(212.4673, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1016.7271, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(0.9455, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(205.2320, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(483.9873, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(370.9055, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1004.2947, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(152.2968, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(39.7097, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(107.8818, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(76.5552, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(273.9165, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(159.4814, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(493.5015, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(228.5494, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(13.1307, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(414.5881, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(477.9321, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(677.8467, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1054.1675, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(111.3141, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(267.2444, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(709.8053, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(39.6345, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(470.1976, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(315.3993, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(319.2727, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(761.5551, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(666.8265, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(70.7784, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(394.3967, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(422.3367, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(239.6249, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(866.7075, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(145.6410, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(494.4726, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(297.3658, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(329.2973, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(210.4274, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(821.2107, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(906.7365, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(113.0912, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(133.9114, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(370.9649, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(30.4492, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(89.2923, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.2231, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(105.9829, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(47.2191, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(324.0505, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(486.8910, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(108.7561, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(613.1387, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(90.5828, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(454.4465, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(224.4562, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(382.9318, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(897.1287, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(359.8487, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.3188, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(409.4553, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(376.4385, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(300.1160, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(413.8014, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1308.0544, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(484.2711, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(522.7307, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(62.1615, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(62.8906, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.3833, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(38.4831, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(174.5093, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(4.5164, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(823.9485, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(508.6910, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(271.4546, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(167.4601, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(11.0999, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(405.4825, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(608.8716, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(362.9965, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(55.8563, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(756.8684, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(313.3364, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(85.2434, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(154.0103, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(56.7935, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(592.0336, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(734.4008, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(403.6005, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(44.9426, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(208.2794, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.3150, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(581.0590, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(88.1850, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(504.4686, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.5299, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(517.2743, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(872.6987, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(587.0914, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(150.9911, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(25.2918, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(245.3790, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(635.9648, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(760.4089, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(250.7512, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(540.7714, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(69.2762, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(225.0244, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(363.1716, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(680.1010, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(317.6084, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(128.4500, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(63.3634, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(231.4855, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.1100, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(71.6757, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(258.7790, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.4607, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(118.2465, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(518.4392, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(116.0134, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(132.9460, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(330.6090, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(775.3749, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(198.7106, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(394.5383, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(338.2040, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(174.5874, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(112.2982, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.9502, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(411.4370, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(513.6925, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(270.3572, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(50.9999, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(527.1929, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(188.7675, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(89.9709, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(369.3800, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(239.4951, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(278.6015, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(161.0737, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(27.6234, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(15.5681, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(126.3906, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(864.2973, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(220.5942, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(760.0155, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(440.1474, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(202.7929, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(21.3801, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(186.4373, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(142.7650, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(697.4459, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(412.2012, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1188.8218, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(410.6060, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(429.5453, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(122.5778, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(86.2906, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(459.4369, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(327.7678, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(98.9881, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(448.7747, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(332.4149, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(280.5437, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.9460, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.3740, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(71.9780, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.7068, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(218.6049, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(774.9716, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(209.7093, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(220.3433, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(8.4452, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(271.7235, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(444.5690, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(104.9056, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(196.5241, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(114.8403, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(243.1315, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(224.3913, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(88.2697, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(126.7191, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(680.9769, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(458.4907, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(467.9148, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(929.7325, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(125.1870, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(762.3930, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(523.3598, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(53.3748, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(318.9191, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(438.0948, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(47.0424, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(308.8321, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(75.2811, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(165.5223, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(814.3046, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(168.1918, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(501.5117, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.4628, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(20.3051, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(333.5338, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.0582, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(263.8274, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(442.9149, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(12.7534, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(247.9595, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(50.1225, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(372.5753, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(478.1127, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(28.6855, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(224.3250, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(10.9451, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(374.5234, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(430.4371, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(87.7970, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.9927, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(171.1514, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(370.3734, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(349.1175, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(563.7301, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(54.3480, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.6923, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(205.5266, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1096.1033, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(484.5251, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(10.3567, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(472.9227, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(448.8940, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(255.1978, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(273.5495, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(120.4309, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(337.6960, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(441.1835, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.6405, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(283.8549, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.5622, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(50.9622, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(411.2273, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(549.8679, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(164.0605, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(991.1404, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(308.6964, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(135.1363, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(116.5377, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(687.1860, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(13.1723, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.7075, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(334.1156, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(374.6404, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.7704, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(206.5624, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(38.4199, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.1489, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(227.3895, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(335.7589, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(888.5770, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(287.9349, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(71.6540, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(625.3392, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(54.1017, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(590.2084, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(111.7884, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(352.6812, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(357.8075, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(220.4731, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(79.2702, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(987.9948, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(186.9166, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(15.3253, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(347.4919, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(185.1028, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(254.2550, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(156.1740, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(132.6108, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(210.9716, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.9701, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1006.8094, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(694.4996, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(99.9601, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(134.0722, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.2956, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(651.7225, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(416.0518, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(535.6974, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(135.2166, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.4312, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(412.1033, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1093.5161, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(457.7158, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(296.9610, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(4.3473, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(83.0100, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(12.7448, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(479.6857, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(55.8177, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(654.1960, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.8581, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(387.3028, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(544.8784, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(126.7539, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(461.7000, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(369.4274, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(230.5491, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(157.1904, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(403.2076, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(157.8844, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1119.0236, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1047.2133, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(102.1617, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(282.7426, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(12.4033, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(341.6660, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(188.2078, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(130.1974, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(343.4776, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(165.0545, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(359.7581, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(48.1219, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(622.2551, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(703.8230, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(371.9572, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(180.0228, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(349.3275, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(723.1590, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(153.2195, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(369.2832, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(58.6179, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(467.4298, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(58.9409, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.5559, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(692.1214, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(162.9110, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(30.6208, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(39.9196, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(579.7389, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(264.2457, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(64.8831, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(327.1189, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(6.3044, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(673.1510, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(128.5902, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(305.3175, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(259.9167, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(437.5407, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(878.0458, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.2072, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(408.4596, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(312.9925, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(277.8289, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(1305.1143, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(498.9804, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(47.0957, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(88.6465, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(397.1980, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(437.7827, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(37.9231, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.6357, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(514.4363, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(224.8215, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(417.1617, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(236.6129, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(641.5668, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(210.4605, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.4506, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(192.0094, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(94.7205, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(258.1302, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(185.3611, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(471.0557, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(167.8686, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(3.9331, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(331.6417, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(614.4702, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(103.6561, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(271.4641, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(520.0271, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(767.7200, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(338.8790, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(80.0583, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(738.0651, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(198.5934, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(311.7556, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(46.1162, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(57.8905, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(70.0306, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(19.6869, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.1113, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(311.1674, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(60.4659, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(23.8003, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(640.8302, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.5117, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(523.7619, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(79.6915, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(16.6088, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(83.8263, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(61.9468, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(80.4441, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(494.2890, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(92.7306, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(130.2069, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(48.5208, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(418.6490, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(12.9195, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(636.8829, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(38.3815, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(22.0461, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(431.1012, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.5697, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(232.2147, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(172.3795, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(8.1969, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.0697, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(287.2295, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(73.4659, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(102.0555, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(186.6344, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(923.4313, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(166.4367, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(268.2169, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(288.2739, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(600.7960, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(79.6013, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(87.4037, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(496.6136, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(498.1071, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(69.6423, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(534.3624, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.5577, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(331.2342, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(210.5306, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(381.1084, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(109.2326, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(549.1019, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.5625, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(762.5396, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(113.4799, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(122.3748, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(400.2675, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(147.7219, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(880.0131, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(245.4476, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(384.8847, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(352.5298, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.7813, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(514.7007, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(268.8752, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(89.8333, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(117.3804, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(166.9668, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(287.4440, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(685.7403, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(245.7921, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(378.6251, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(246.1635, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(189.3754, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(611.8984, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(328.4796, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(144.3309, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(249.2346, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(35.5663, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(271.4577, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(117.8414, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(182.9610, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(247.4655, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.8719, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(30.7570, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(432.8558, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(286.6718, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(639.1102, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(29.7383, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(247.0892, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(249.0945, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(71.1516, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(85.3713, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(499.7945, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.8316, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(393.2041, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(280.7754, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(546.9777, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(190.1937, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(519.9162, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(519.1151, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(322.1840, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(51.1734, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(487.5696, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.8103, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.1957, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(233.9048, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(101.4357, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(442.7466, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(41.2363, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(280.1857, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(192.0071, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(37.9684, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(411.3022, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(465.8088, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(92.9897, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(102.7383, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(542.1566, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(209.7422, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(598.4320, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(384.7742, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(664.6282, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(76.2885, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(20.6420, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(293.4930, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(32.8017, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(707.2397, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(74.5707, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(331.9058, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "0\n",
      "RSS at n=0 tensor(nan)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(nan, grad_fn=<NormBackward1>)\n",
      "Loss after: tensor(nan, grad_fn=<CopyBackwards>)\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss for b is tensor(nan, grad_fn=<NormBackward1>) at iteration 0\n",
      "1\n",
      "RSS at n=1 tensor(nan)\n",
      "It took: 349.6636784000002 seconds to finish running\n",
      "The best RSS value was tensor(nan)\n",
      "[tensor(nan), tensor(nan)]\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "torch.manual_seed(42)\n",
    "\n",
    "RSS_values = list()\n",
    "A = np.zeros((K,N))#.tolist()\n",
    "B = np.zeros((N,K))#.tolist()\n",
    "\n",
    "# LOOP UNTIL RSS IS LOW\n",
    "for n in range(2): #N\n",
    "    Q = Z.T @ Z\n",
    "    Qt = torch.tensor(Q,requires_grad=False).float()\n",
    "\n",
    "    # LOOP THROUGH ENTIRE A\n",
    "    for i in range(N):\n",
    "        q = Z.T @ X[:,i]\n",
    "        qt = torch.tensor(q,requires_grad=False).float()\n",
    "        \n",
    "        if n == 0:\n",
    "            a_i = torch.autograd.Variable(torch.rand(K, 1), requires_grad=True) # eller er det Kx1 ?\n",
    "            optimizer_a = optim.SGD([a_i], lr=0.01)\n",
    "        \n",
    "        stop_loss = 1e-5\n",
    "        step_size = 0.001 # stop_loss / 3.0\n",
    "\n",
    "        err = error(a_i,Qt,qt) \n",
    "        #(0.5 * a_i.T @ Qt @ a_i) - (qt.T @ a_i)\n",
    "        print('Loss before: %s' % (torch.norm( err, p=2)))\n",
    "\n",
    "        # TRAINING LOOP\n",
    "        for k in range(100): # 100000\n",
    "            optimizer_a.zero_grad()\n",
    "            #Delta = error(a_i,Qt,qt) \n",
    "            L = error(a_i,Qt,qt)      # error needs norm(X_i^2)\n",
    "            L.backward()\n",
    "            optimizer_a.step()\n",
    "            #a_i.data -= step_size * a_i.grad.data # step\n",
    "            #a_i.grad.data.zero_()\n",
    "            \n",
    "            #### --> Look at gradient instead - draw it from L.backward()\n",
    "            \n",
    "            #if k % 10000 == 0: print('Loss for a is %s at iteration %i' % (L, k))\n",
    "            #if abs(L) < stop_loss:\n",
    "                #print('It took %s iterations to achieve %s loss.' % (k, step_size))\n",
    "                #break\n",
    "        \n",
    "        A[:,i] = np.array(a_i.tolist()).flatten() \n",
    "        \n",
    "        print('Loss after: %s' % (torch.norm( error(a_i,Qt,qt) )))\n",
    "    \n",
    "    A = applyConstrains(A)\n",
    "    Z = X @ A.T @ np.linalg.inv(A@A.T)\n",
    "    \n",
    "    \n",
    "    # LOOP THROUGH ENTIRE B\n",
    "    for i in range(K): #K\n",
    "        r = X.T @ Z[:,i]\n",
    "        rt = torch.tensor(r,requires_grad=False).float()\n",
    "        \n",
    "        if n == 0:\n",
    "            b_i = torch.autograd.Variable(torch.randn(N,1), requires_grad=True)\n",
    "            optimizer_b = optim.Adam([b_i], lr=0.01)\n",
    "        \n",
    "        \n",
    "        stop_loss = 1e-5\n",
    "        step_size = 0.001 # stop_loss / 3.0\n",
    "\n",
    "        err = error(b_i,Rt,rt)\n",
    "        #print('Loss before: %s' % (torch.norm( err, p=2)))\n",
    "\n",
    "        # TRAINING LOOP\n",
    "        for k in range(10000): # 100000\n",
    "            optimizer_b.zero_grad()\n",
    "            Delta = error(b_i,Rt,rt)\n",
    "            L = torch.norm(Delta, p=2)\n",
    "            L.backward()\n",
    "            optimizer_b.step()\n",
    "            \n",
    "            # b_i.data -= step_size * b_i.grad.data # step\n",
    "            # b_i.grad.data.zero_()\n",
    "            if k % 10000 == 0: print('Loss for b is %s at iteration %i' % (L, k))\n",
    "            if abs(L) < stop_loss:\n",
    "                print('It took %s iterations to achieve %s loss.' % (k, step_size))\n",
    "                break\n",
    "\n",
    "        B[:,i] = np.array(b_i.tolist()).flatten() \n",
    "        #print('Loss after: %s' % (torch.norm( error(b_i,Rt,rt) )))    \n",
    "    \n",
    "    # apply softmax here\n",
    "    B = applyConstrains(B)\n",
    "    Z = X @ B\n",
    "    \n",
    "    print(n)\n",
    "    Zt = torch.tensor(Z, requires_grad=False).float()\n",
    "    At = torch.tensor(A, requires_grad=False).float()\n",
    "    Xt = torch.tensor(X,requires_grad=False).float()\n",
    "    print(\"RSS at n=%s\" % n, torch.norm(Xt-Zt@At,p='fro')**2)  #does 'fro' take squared? \n",
    "    RSS_values.append( torch.norm(Xt-Zt@At,p='fro')**2)\n",
    "    \n",
    "end = timer()\n",
    "\n",
    "print(\"It took: {0} seconds to finish running\".format(end - start))\n",
    "print(\"The best RSS value was\", min(RSS_values))\n",
    "print(RSS_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adbd8a",
   "metadata": {},
   "source": [
    "## Time at datasize 1000 x 17 for:\n",
    "### Adam\n",
    "$\\textbf{Time}$ in seconds: 351.60987780000005 \n",
    "\n",
    "$\\textbf{RSS:}$ 160.3371 \n",
    "\n",
    "$\\textbf{Step size:}$ 0.00001\n",
    "\n",
    "$\\textbf{Stop loss:}$ $1\\cdot 10^{-6}$\n",
    "\n",
    "$\\textbf{Learning rate:}$ 0.05\n",
    "\n",
    "____________________________________________\n",
    "$\\textbf{Time}$ in seconds: 288.2289836 \n",
    "\n",
    "$\\textbf{RSS:}$ 160.4064\n",
    "\n",
    "$\\textbf{Step size:}$ 0.001\n",
    "\n",
    "$\\textbf{Stop loss:}$ $1\\cdot 10^{-5}$\n",
    "\n",
    "$\\textbf{Learning rate:}$ 0.01\n",
    "\n",
    "_____________________________________________\n",
    "\n",
    "### Ordinal GD(?)\n",
    "$\\textbf{Time}$ in seconds: 236.4697258000001\n",
    "\n",
    "$\\textbf{RSS:}$ 160.3474\n",
    "\n",
    "$\\textbf{Step size:}$ 0.00001\n",
    "\n",
    "$\\textbf{Stop loss:}$ $1\\cdot 10^{-6}$\n",
    "______________________________________________\n",
    "\n",
    "$\\textbf{Time}$ in seconds: 220.46896449999986\n",
    "\n",
    "$\\textbf{RSS:}$ 160.3430\n",
    "\n",
    "$\\textbf{Step size:}$ 0.001\n",
    "\n",
    "$\\textbf{Stop loss:}$ $1\\cdot 10^{-5}$\n",
    "\n",
    "____________________________________________\n",
    "### SGD\n",
    "$\\textbf{Time}$ in seconds: Never converged\n",
    "\n",
    "$\\textbf{RSS:}$ never converged $\\rightarrow$ loss after for $\\textbf{a}_i$ was consistently inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cfbdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AA:\n",
    "    \"\"\"\n",
    "    Class for applying conventional archetypal analysis.\n",
    "    \n",
    "    Input: \n",
    "    X = M x N matrix of data (features x samples)\n",
    "    \n",
    "    K = number of archetypes to be computed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, K):\n",
    "        \n",
    "        self.M, self.N = X.shape\n",
    "        self.X = X\n",
    "        self.Rt = torch.tensor(X.T @ X,requires_grad=False).float()\n",
    "        self.K = K\n",
    "    \n",
    "    \n",
    "    def applyConstraints(self, A):\n",
    "        return softmax(A, axis = 0)\n",
    "    \n",
    "    def error(self, a_i, Qt, qt):\n",
    "        return (0.5 * a_i.T @ Qt @ a_i) - (qt.T @ a_i)\n",
    "        \n",
    "    \n",
    "    def furthestSum(self):\n",
    "        # Choose a random point for initialization\n",
    "        idx = int(np.random.choice(range(0,N)))\n",
    "        x_j = self.X[:,idx]\n",
    "\n",
    "        j_news = list()\n",
    "        j_news.append(idx)\n",
    "\n",
    "        excluded = [idx]\n",
    "\n",
    "        # Loop over the K archetypes\n",
    "        for n in range(self.K):\n",
    "            best_val = 0\n",
    "            best_idx = 0\n",
    "            # Loop over all unseen samples\n",
    "            for i in range(N-len(excluded)):\n",
    "                if i not in excluded:\n",
    "                    val = 0\n",
    "                    # sum over each element for each point\n",
    "                    for ele in j_news:\n",
    "                        for j in range(M):\n",
    "\n",
    "                            val += np.abs(self.X[j,i] - self.X[j , ele])\n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        best_idx = i\n",
    "\n",
    "            j_news.append(int(best_idx))\n",
    "            excluded.append(best_idx)\n",
    "            # Remove the random initialization\n",
    "            if n == 0:\n",
    "                j_news.pop(0)\n",
    "                excluded.pop(0)\n",
    "        return j_news\n",
    "\n",
    "    \"\"\"\n",
    "    Function for applying conventional archetypal analysis:\n",
    "    -----------------------------------------------------------------------\n",
    "        Inputs: \n",
    "            self\n",
    "            Z: Matrix that will contain the archetypes, initialize the values using furthestSum\n",
    "            time: Boolean, if True the time of convergence will be measured\n",
    "            lr: Learning rate for the optimizer\n",
    "            stop_loss: stop loss value for the inner loop\n",
    "            amsgrad: Boolean, if True uses the \"amsgrad\" method for Adam optimizer\n",
    "            n_outer: Number of iterations to run the outermost loop\n",
    "            n_inner: Number of iterations to run the inner loop\n",
    "    \"\"\"\n",
    "    def applyAA(self, Z, time = True, lr = 0.01, stop_loss=1e-05, amsgrad=True, n_outer=2, n_inner=1000):\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        if time == True:\n",
    "            start = timer()\n",
    "\n",
    "        RSS_values = list()\n",
    "        A = np.zeros((self.K, self.N))#.tolist()\n",
    "        B = np.zeros((self.N, self.K))#.tolist()\n",
    "\n",
    "        # LOOP UNTIL RSS IS LOW\n",
    "        for n in range(n_outer):\n",
    "            Q = Z.T @ Z\n",
    "            Qt = torch.tensor(Q,requires_grad=False).float()\n",
    "\n",
    "            # LOOP THROUGH ENTIRE A\n",
    "            for i in range(self.N):\n",
    "                q = Z.T @ self.X[:,i]\n",
    "                qt = torch.tensor(q,requires_grad=False).float()\n",
    "\n",
    "                if n == 0:\n",
    "                    a_i = torch.autograd.Variable(torch.rand(self.K, 1), requires_grad=True) # eller er det Kx1 ?\n",
    "                    optimizer_a = optim.Adam([a_i], lr=0.01, amsgrad = amsgrad)\n",
    "\n",
    "                \n",
    "\n",
    "                err = error(a_i,Qt,qt)\n",
    "                print('Loss before: %s' % (torch.norm( err, p=2)))\n",
    "\n",
    "                # TRAINING LOOP\n",
    "                for k in range(n_inner): # 100000\n",
    "                    optimizer_a.zero_grad()\n",
    "                    Delta = error(a_i,Qt,qt) \n",
    "                    L = torch.norm(Delta, p=2)\n",
    "                    L.backward()\n",
    "                    optimizer_a.step()\n",
    "                    \n",
    "                    if k % 10000 == 0: print('Loss for a is %s at iteration %i' % (L, k))\n",
    "                    if abs(L) < stop_loss:\n",
    "                        print('It took %s iterations to achieve %s loss.' % (k, step_size))\n",
    "                        break\n",
    "\n",
    "                A[:,i] = np.array(a_i.tolist()).flatten() \n",
    "\n",
    "                print('Loss after: %s' % (torch.norm( error(a_i,Qt,qt) )))\n",
    "\n",
    "            A = applyConstrains(A)\n",
    "            Z = self.X @ A.T @ np.linalg.inv(A@A.T)\n",
    "\n",
    "\n",
    "            # LOOP THROUGH ENTIRE B\n",
    "            for i in range(self.K): #K\n",
    "                r = self.X.T @ Z[:,i]\n",
    "                rt = torch.tensor(r,requires_grad=False).float()\n",
    "\n",
    "                if n == 0:\n",
    "                    b_i = torch.autograd.Variable(torch.randn(self.N,1), requires_grad=True)\n",
    "                    optimizer_b = optim.Adam([b_i], lr= lr, amsgrad = amsgrad)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                err = error(b_i, self.Rt, rt)\n",
    "                # print('Loss before: %s' % (torch.norm( err, p=2)))\n",
    "\n",
    "                # TRAINING LOOP\n",
    "                for k in range(n_inner):\n",
    "                    optimizer_b.zero_grad()\n",
    "                    Delta = error(b_i, self.Rt,rt)\n",
    "                    L = torch.norm(Delta, p=2)\n",
    "                    L.backward()\n",
    "                    optimizer_b.step()\n",
    "\n",
    "                    # b_i.data -= step_size * b_i.grad.data # step\n",
    "                    # b_i.grad.data.zero_()\n",
    "                    if k % 10000 == 0: print('Loss for b is %s at iteration %i' % (L, k))\n",
    "                    if abs(L) < stop_loss:\n",
    "                        print('It took %s iterations to achieve %s loss.' % (k, step_size))\n",
    "                        break\n",
    "\n",
    "                B[:,i] = np.array(b_i.tolist()).flatten() \n",
    "                #print('Loss after: %s' % (torch.norm( error(b_i,Rt,rt) )))    \n",
    "\n",
    "            # apply softmax here\n",
    "            B = applyConstrains(B)\n",
    "            Z = self.X @ B\n",
    "\n",
    "            Zt = torch.tensor(Z, requires_grad=False).float()\n",
    "            At = torch.tensor(A, requires_grad=False).float()\n",
    "            Xt = torch.tensor(self.X,requires_grad=False).float()\n",
    "            print(\"RSS at n=%s\" % n, torch.norm(Xt-Zt@At, p='fro'))\n",
    "            RSS_values.append( torch.norm(Xt-Zt@At, p='fro'))\n",
    "        if time == True:\n",
    "            end = timer()\n",
    "            print(\"It took: {0} seconds to finish running\".format(end - start))\n",
    "            \n",
    "        print(\"The best RSS value was\", min(RSS_values))\n",
    "        \n",
    "        return RSS_values, Z, B, A\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95b106",
   "metadata": {},
   "source": [
    "### Testing the class\n",
    "##### Defining variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06b0857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 1000)\n"
     ]
    }
   ],
   "source": [
    "X = df[['SD1', 'PO1', 'UN1', 'AC1', 'SC1',\n",
    "       'ST1', 'CO1', 'UN2', 'TR1', 'HD1', 'SD2','BE1','AC2', 'SC2', 'ST2',\n",
    "       'CO2', 'PO2', 'BE2', 'UN3', 'TR2','HD2']].iloc[range(100),:]\n",
    "\n",
    "X = X.to_numpy()\n",
    "X = X.T\n",
    "print(X.shape)\n",
    "K = 5\n",
    "\n",
    "lr = 0.01\n",
    "stop_loss = 1e-05\n",
    "armsgrad = True\n",
    "time = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0419dfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before: tensor(789.0945, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(789.0945, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.3415, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(416.0961, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(416.0961, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(2.5127, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(694.3499, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(694.3499, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6056, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(200.2817, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(200.2817, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.3930, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.3585, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(148.3585, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8758, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(17.6309, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(17.6309, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6827, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(538.1461, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(538.1461, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(2.0982, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(580.1072, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(580.1072, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8638, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(684.3636, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(684.3636, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(2.6873, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(274.5775, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(274.5775, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4017, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(57.1619, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(57.1619, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.1305, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(573.2366, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(573.2366, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.3571, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(315.3781, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(315.3781, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4834, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(5.3409, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(5.3409, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6619, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(148.9496, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(148.9496, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.2029, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(268.0377, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(268.0377, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.3193, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(175.1602, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(175.1602, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.0171, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(36.4431, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(36.4431, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.2696, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(578.3174, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(578.3174, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.1745, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(65.9276, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(65.9276, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.0460, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(49.4328, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(49.4328, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6375, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(82.8306, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(82.8306, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.4218, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(371.1699, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(371.1699, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6158, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(45.2990, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(45.2990, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.7477, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(54.9836, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(54.9836, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4204, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(236.6675, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(236.6675, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.0853, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(686.9150, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(686.9150, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.7071, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(43.8681, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(43.8681, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.3860, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(221.3438, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(221.3438, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.0794, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(806.3693, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(806.3693, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4010, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(86.2949, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(86.2949, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(3.8434, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(207.2958, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(207.2958, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.8853, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(364.7152, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(364.7152, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4256, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(260.3900, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(260.3900, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.9721, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(9.5020, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(9.5020, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.0370, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(321.3445, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(321.3445, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(2.0733, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(300.0396, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(300.0396, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.5844, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(225.9975, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(225.9975, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6795, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(615.4878, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(615.4878, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.3296, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(335.4227, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(335.4227, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8971, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(121.9533, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(121.9533, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.4856, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(16.4429, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(16.4429, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.6780, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(146.6775, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(146.6775, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8903, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(565.4977, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(565.4977, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.2548, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(61.4538, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(61.4538, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8780, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(326.8290, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(326.8290, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.9090, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(424.8587, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(424.8587, grad_fn=<NormBackward1>) at iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after: tensor(0.8954, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(106.7076, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(106.7076, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.5074, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(151.4555, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(151.4555, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.8972, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(81.0436, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(81.0436, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.0302, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(86.0173, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(86.0173, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.9207, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(128.8573, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(128.8573, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(0.8256, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(392.5201, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(392.5201, grad_fn=<NormBackward1>) at iteration 0\n",
      "Loss after: tensor(1.7514, grad_fn=<CopyBackwards>)\n",
      "Loss before: tensor(400.6244, grad_fn=<NormBackward1>)\n",
      "Loss for a is tensor(400.6244, grad_fn=<NormBackward1>) at iteration 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28212/3944687190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAA_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAA_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfurthestSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mAA_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplyAA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_inner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28212/3437050119.py\u001b[0m in \u001b[0;36mapplyAA\u001b[1;34m(self, Z, time, lr, stop_loss, amsgrad, n_outer, n_inner)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0moptimizer_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0mDelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                     \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                     \u001b[0moptimizer_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AA_model = AA(X, K)\n",
    "Z = AA_model.X[:,AA_model.furthestSum()]\n",
    "\n",
    "RSS, Z, A, B = AA_model.applyAA(Z = Z, time = True, lr = 0.01, stop_loss=1e-05, amsgrad=True, n_outer=2, n_inner=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54d93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef5c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380c9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7899935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163d0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6512107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
